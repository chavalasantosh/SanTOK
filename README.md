# Krishna Tokenizer

**Enterprise-grade text tokenization platform with multiple algorithms, compression analysis, and real-time visualization.**

## 🚀 Quick Start

### Python CLI (Original)
```bash
python krishna_tokenizer.py
```

### Web Frontend (New)
```bash
cd frontend
npm install
npm run dev
```

## 📁 Project Structure

```
Krisna Tokenization/
├── frontend/                 # 🌐 Web Application (Next.js)
│   ├── app/                 # Next.js pages
│   ├── components/          # React components
│   ├── lib/                 # API integration
│   ├── store/               # State management
│   └── ...                  # Frontend files
├── docs/                    # 📚 Documentation
├── examples/                # 🧪 Demo scripts
├── tests/                   # 🧪 Test suite
├── krishna_tokenizer.py     # 🐍 Main Python CLI
├── main.py                  # 🐍 Entry point
├── tokenizer.py             # 🐍 Core tokenizer
├── token_math.py            # 🐍 Math utilities
└── uid.py                   # 🐍 UID generation
```

## 🎯 Features

### Python CLI
- ✅ 9 Tokenization algorithms
- ✅ Compression analysis
- ✅ Performance metrics
- ✅ File processing
- ✅ Command-line interface

### Web Frontend
- ✅ Interactive dashboard
- ✅ Real-time tokenization
- ✅ File upload support
- ✅ Visual analytics
- ✅ Dark mode
- ✅ Responsive design

## 🛠️ Technology Stack

### Backend (Python)
- **Core**: Python 3.8+
- **Libraries**: Standard library
- **Features**: Multiple tokenization algorithms

### Frontend (Web)
- **Framework**: Next.js 14 + TypeScript
- **Styling**: Tailwind CSS + shadcn/ui
- **Charts**: Recharts
- **State**: Zustand
- **Animations**: Framer Motion

## 📖 Documentation

- [Complete User Manual](docs/02-user-guides/01-Complete_User_Manual.md)
- [Quick Start Guide](docs/02-user-guides/02-Quick_Start_Guide.md)
- [Technical Specifications](docs/03-technical-specs/)
- [Mathematics Reference](docs/04-mathematics/)

## 🚀 Getting Started

### Option 1: Python CLI
```bash
# Run the main tokenizer
python krishna_tokenizer.py

# Or use the entry point
python main.py
```

### Option 2: Web Frontend
```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev

# Open http://localhost:3000
```

## 🧪 Examples

```bash
# Run demo scripts
python examples/demo_enhanced_tokenization.py
python examples/demo_stable_system.py
python examples/demo_universal_files.py
```

## 🧪 Testing

```bash
# Run all tests
python tests/run_tests.py

# Run specific test suites
python tests/test_scripts/test_comprehensive.py
python tests/test_scripts/test_compression_efficiency.py
```

## 📊 Supported Tokenizers

1. **Character** - Individual character tokenization
2. **Word** - Word boundary tokenization
3. **Space** - Whitespace-based tokenization
4. **Subword** - Advanced subword tokenization
5. **Grammar** - Linguistic grammar-based tokenization
6. **Syllable** - Syllable-based tokenization
7. **Byte** - Byte-level tokenization
8. **BPE** - Byte Pair Encoding
9. **Frequency** - Frequency-based tokenization

## 🎨 Web Interface Features

- **Dashboard** - Main tokenization interface
- **Compression Explorer** - Algorithm comparison
- **Performance Lab** - Benchmarking tools
- **About** - Project information

## 📱 Responsive Design

- **Desktop** - Full feature set
- **Tablet** - Touch-optimized
- **Mobile** - Stacked layout

## 🔧 Configuration

### Environment Variables
```env
# Frontend (.env.local)
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### Tokenizer Options
- Lowercase text
- Drop special characters
- Collapse repeats
- Enable embeddings
- Custom seed
- Embedding bit control

## 🚀 Deployment

### Python CLI
- Run directly on any Python 3.8+ system
- No additional dependencies required

### Web Frontend
- Deploy to Vercel, Netlify, or any hosting platform
- Build command: `npm run build`
- Start command: `npm start`

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## 📄 License

MIT License - see LICENSE file for details

## 🆘 Support

- **Documentation**: Check the `docs/` folder
- **Issues**: Create a GitHub issue
- **Email**: support@krishnatokenizer.com

---

**Krishna Tokenizer** - Advanced text processing made simple and powerful.
