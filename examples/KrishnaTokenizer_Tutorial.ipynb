{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Krishna Tokenizer — Counting and Inspecting Tokens\n",
        "\n",
        "This notebook demonstrates how to tokenize chaotic text (including emojis, punctuation, mixed case, repeats), compute frontend digits (0–9), and generate backend numbers (huge and scaled), similar in spirit to the tiktoken token counting guide.\n",
        "\n",
        "Reference: [How_to_count_tokens_with_tiktoken.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
        "\n",
        "## What you’ll learn\n",
        "- Preserve-all tokenization (space/word/char/grammar/subword/byte)\n",
        "- Frontend digits (0–9) per token\n",
        "- Backend numbers (full M and scaled small-IDs)\n",
        "- Digit-only streams (flattened 0–9)\n",
        "- Determinism and validation (checksums, lengths)\n",
        "- DEV vs USER vs JSON output styles\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Start\n",
        "\n",
        "Run the CLI for interactive exploration:\n",
        "\n",
        "```bash\n",
        "python krishna_tokenizer.py\n",
        "```\n",
        "\n",
        "- Choose input: type text or provide a file path\n",
        "- Choose output mode: DEV (full), USER (summary), JSON (compact)\n",
        "- Optionally save per-stream JSONL files\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Input\n",
        "\n",
        "```text\n",
        "mother Fucker :), @nIpuKuLLO Naaaaaaa mOOOOOOOdAAAAAAAA.\n",
        "```\n",
        "\n",
        "This input includes spaces, punctuation, symbols, mixed case, and repeats. The system keeps everything intact for display; numbers are computed on a math view (lowercased, repeat-aware), while preserving all original characters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization Levels\n",
        "\n",
        "- Space tokens: split on spaces\n",
        "- Word tokens: alphanumerics grouped; punctuation separated\n",
        "- Grammar tokens: words and individual punctuation/emojis\n",
        "- Character tokens: one token per character\n",
        "- Subword tokens: fixed n-grams (3 chars)\n",
        "- Byte tokens: decimal digits of codepoints (UTF-8-free fallback)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Frontend and Backend\n",
        "\n",
        "For each token:\n",
        "- frontend: a digit 1–9 (Krishna-digit)\n",
        "- backend_huge: full identity number M (deterministic, large)\n",
        "- backend_scaled: small readable ID (0..99999)\n",
        "- backend_digits: flattened 0–9 digit stream from backend_scaled\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DEV vs USER vs JSON Modes\n",
        "\n",
        "- DEV: full debug (all token lists, digits, backends, IDs)\n",
        "- USER: concise summary (word tokens, frontend digits, backend_digits)\n",
        "- JSON: compact machine-readable summary\n",
        "\n",
        "This mirrors the style of the tiktoken doc while preserving Krishna-specific math.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- tiktoken counting tutorial: [How_to_count_tokens_with_tiktoken.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)\n",
        "- This Krishna tokenizer preserves all characters; math view only normalizes for stability.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
